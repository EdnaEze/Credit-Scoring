{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hEades1EzQRA7k_Go2HsU8gilH4U9qAE",
      "authorship_tag": "ABX9TyOlnV4XW/anARpzdxSl45Ay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdnaEze/Credit-Scoring/blob/main/new_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Azgc4Zzum3Ng"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ee278/ANLP assignment/propaganda_dataset_v2/propaganda_train.tsv\", delimiter=\"\\t\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/ee278/ANLP assignment/propaganda_dataset_v2/propaganda_val.tsv\", delimiter=\"\\t\")"
      ],
      "metadata": {
        "id": "M9mB-JyDnZju"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "train_sentences = [sentence.split() for sentence in train_data[\"tagged_in_context\"]]\n",
        "test_sentences = [sentence.split() for sentence in test_data[\"tagged_in_context\"]]\n",
        "train_labels = train_data[\"label\"]\n",
        "test_labels = test_data[\"label\"]\n",
        "\n",
        "train_labels_task2 = [0 if label==\"not_propaganda\" else 1 for label in train_labels]\n",
        "test_labels_task2 = [0 if label==\"not_propaganda\" else 1 for label in test_labels]"
      ],
      "metadata": {
        "id": "2uzhd6kgqsqk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define labels for task 1\n",
        "label_map = {\"not_propaganda\": 0,\n",
        "             \"flag_waving\": 1, \n",
        "             \"appeal_to_fear_prejudice\": 2, \n",
        "             \"causal_oversimplification\": 3, \n",
        "             \"doubt\": 4, \n",
        "             \"exaggeration,minimisation\": 5, \n",
        "             \"loaded_language\": 6, \n",
        "             \"name_calling,labeling\": 7, \n",
        "             \"repetition\": 8\n",
        "             }\n",
        "\n",
        "train_labels_task1 = [label_map[label] for label in train_labels]\n",
        "test_labels_task1 = [label_map[label] for label in test_labels]"
      ],
      "metadata": {
        "id": "R3kwd1GOCyKW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Word2Vec model\n",
        "w2v_model = Word2Vec(train_sentences, vector_size=300, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "HAp86nyIqstE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function to convert sentences to vectors using Word2Vec model\n",
        "def sentence_to_vec(sentence, model):\n",
        "    vec = np.zeros(300)\n",
        "    count = 0\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            vec += model.wv[word]\n",
        "            count += 1\n",
        "        except KeyError:\n",
        "            pass\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "metadata": {
        "id": "qT7FoApDqsw6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert sentences to vectors using Word2Vec model\n",
        "train_embeddings = [sentence_to_vec(sentence, w2v_model) for sentence in train_sentences]\n",
        "test_embeddings = [sentence_to_vec(sentence, w2v_model) for sentence in test_sentences]"
      ],
      "metadata": {
        "id": "tgDttDNZqs4X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a logistic regression classifier for task 1\n",
        "lr1 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
        "lr1.fit(train_embeddings, train_labels)\n",
        "\n",
        "predictions1 = lr1.predict(test_embeddings)\n",
        "accuracy1 = accuracy_score(test_labels, predictions1)\n",
        "report1 = classification_report(test_labels, predictions1, target_names=label_map.keys(), zero_division=1)"
      ],
      "metadata": {
        "id": "ROs-JzP2r18g"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"Task 1 accuracy: \", accuracy1)\n",
        "print(\"Task 1 classification report:\\n\", report1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrRTr-3hr2AF",
        "outputId": "0e48497e-e8a2-4a84-bf36-77ea454c52f3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 accuracy:  0.5189655172413793\n",
            "Task 1 classification report:\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "           not_propaganda       1.00      0.00      0.00        43\n",
            "              flag_waving       1.00      0.00      0.00        31\n",
            " appeal_to_fear_prejudice       1.00      0.00      0.00        38\n",
            "causal_oversimplification       1.00      0.00      0.00        28\n",
            "                    doubt       1.00      0.00      0.00        39\n",
            "exaggeration,minimisation       1.00      0.00      0.00        37\n",
            "          loaded_language       1.00      0.00      0.00        31\n",
            "    name_calling,labeling       0.52      1.00      0.68       301\n",
            "               repetition       1.00      0.00      0.00        32\n",
            "\n",
            "                 accuracy                           0.52       580\n",
            "                macro avg       0.95      0.11      0.08       580\n",
            "             weighted avg       0.75      0.52      0.35       580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a logistic regression classifier for task 2\n",
        "lr2 = LogisticRegression(random_state=42, multi_class=\"ovr\", solver=\"newton-cg\")\n",
        "lr2.fit(train_embeddings, train_labels_task2)\n",
        "\n",
        "predictions2 = lr2.predict(test_embeddings)\n",
        "accuracy2 = accuracy_score(test_labels_task2, predictions2)\n",
        "report2 = classification_report(test_labels_task2, predictions2, target_names=[\"not_propaganda\", \"propaganda\"])"
      ],
      "metadata": {
        "id": "2QA_niPJr1-D"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Task 2 accuracy: \", accuracy2)\n",
        "print(\"Task 2 classification report:\\n\", report2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2waFauDLZf7",
        "outputId": "e141e122-aeab-41db-c05e-7a4bf54949ae"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2 accuracy:  0.5586206896551724\n",
            "Task 2 classification report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_propaganda       0.55      0.77      0.64       301\n",
            "    propaganda       0.57      0.33      0.42       279\n",
            "\n",
            "      accuracy                           0.56       580\n",
            "     macro avg       0.56      0.55      0.53       580\n",
            "  weighted avg       0.56      0.56      0.54       580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMV-fDGVr2Gq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}